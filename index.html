<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description" content="Temporal In-Context Fine-Tuning for Versatile Control of Video Diffusion Models">
  <meta name="keywords" content="Video Diffusion Models, Temporal In-Context, Fine-Tuning, Video Control">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Cartoon to Video Demo</title>

  <!-- Google Fonts -->
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

  <!-- CSS -->
  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>

  <style>
    .media-row {
      display: flex;
      justify-content: center;
      align-items: flex-start;
      gap: 16px;
      max-width: 1200px;
      margin: 20px auto 0 auto;
      padding: 0 8px;
      width: 100%;
    }
  
    .media-cell {
      flex: 1;
      max-width: 100%;
      display: flex;
      flex-direction: column;
      align-items: center;
    }
  
    .media-cell img,
    .media-cell video {
      width: 100%;
      height: auto;
      object-fit: contain;
      image-rendering: auto;
      border-radius: 0;
      box-shadow: 0 2px 12px rgba(0, 0, 0, 0.08);
    }
  
    /* 줄의 전체 너비는 유지하고, 한 줄에 있는 모든 셀은 균등 분배되게 */
    .media-row.two-columns .media-cell {
      width: calc((100% - 16px) / 2);
    }
  
    .media-row.three-columns .media-cell {
      width: calc((100% - 2 * 16px) / 3);
    }
  
    /* 반응형 대응 */
    @media screen and (max-width: 768px) {
      .media-row {
        flex-direction: column;
        gap: 16px;
      }
      .media-cell {
        width: 100% !important;
      }
    }
  </style>  
</head>
<body>

<nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
  <div class="navbar-menu">
    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
      <a class="navbar-item" href="https://junhahyung.github.io/">
        <span class="icon">
          <i class="fas fa-home"></i>
        </span>
      </a>
    </div>
  </div>
</nav>

<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">
            Temporal In-Context Fine-Tuning<br>for Versatile Control of Video Diffusion Models
          </h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://kinam0252.github.io/" target="_blank" rel="noopener noreferrer">Kinam Kim*</a>,
            </span>
            <span class="author-block">
              <a href="https://junhahyung.github.io/" target="_blank" rel="noopener noreferrer">Junha Hyung*</a>,
            </span>
            <span class="author-block">
              <a href="https://sites.google.com/site/jaegulchoo/" target="_blank" rel="noopener noreferrer">Jaegul Choo</a>
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block">KAIST AI</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <span class="link-block">
                <a href="https://github.com/kinam0252/TIC-FT"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                </a>
              </span>
              <span class="link-block">
                <a href="https://arxiv.org/abs/2411.18664" class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            We present Temporal In-Context Fine-Tuning (TIC-FT), a simple and efficient method for adapting pretrained video diffusion models to a wide range of conditional generation tasks. TIC-FT works by concatenating condition and target frames along the temporal axis and inserting buffer frames with increasing noise, enabling smooth transitions and alignment with the model's temporal dynamics. Unlike prior approaches, TIC-FT requires no architectural changes or large datasets, and achieves strong performance with as few as 10–30 training samples. We demonstrate its effectiveness on tasks such as image-to-video and video-to-video generation using large-scale models, showing superior condition fidelity, visual quality, and efficiency compared to existing baselines.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <h2 class="title is-3" style="font-weight: bold; margin-top: 40px;">Image-To-Video</h2>
    <div class="content has-text-justified" style="margin-bottom: 20px;">
      <p>
        This task generates a full video conditioned on a single image. The image may represent a high-level concept—such as a character profile or a top-view object—with the video depicting novel dynamics, such as a character-centric animation or a 360° rotation.
      </p>
    </div>
    <div class="media-row">
      <div class="media-cell">
        <img src="assets/CartoonToVideo/1-1.png" alt="Cartoon Input 1">
      </div>
      <div class="media-cell">
        <video class="autoplay-loop-video" src="assets/CartoonToVideo/1-2.mp4" controls autoplay loop muted></video>
      </div>
    </div>
    <div class="media-row">
      <div class="media-cell">
        <img src="assets/CartoonToVideo/2-1.png" alt="Cartoon Input 2">
      </div>
      <div class="media-cell">
        <video class="autoplay-loop-video" src="assets/CartoonToVideo/2-2.mp4" controls autoplay loop muted></video>
      </div>
    </div>
    <div class="media-row">
      <div class="media-cell">
        <img src="assets/3DToVideo/1-1.png" alt="3DToVideo 1-1">
      </div>
      <div class="media-cell">
        <video class="autoplay-loop-video" src="assets/3DToVideo/1-2.mp4" controls autoplay loop muted></video>
      </div>
    </div>
    <div class="media-row">
      <div class="media-cell">
        <img src="assets/3DToVideo/2-1.png" alt="3DToVideo 2-1">
      </div>
      <div class="media-cell">
        <video class="autoplay-loop-video" src="assets/3DToVideo/2-2.mp4" controls autoplay loop muted></video>
      </div>
    </div>
    <div class="media-row">
      <div class="media-cell">
        <img src="assets/CharacterToVideo/1-1.png" alt="CharacterToVideo 1-1">
      </div>
      <div class="media-cell">
        <video class="autoplay-loop-video" src="assets/CharacterToVideo/1-2.mp4" controls autoplay loop muted></video>
      </div>
      <div class="media-cell">
        <img src="assets/CharacterToVideo/2-1.png" alt="CharacterToVideo 2-1">
      </div>
      <div class="media-cell">
        <video class="autoplay-loop-video" src="assets/CharacterToVideo/2-2.mp4" controls autoplay loop muted></video>
      </div>
    </div>

    <div class="media-row">
      <div class="media-cell">
        <img src="assets/360/1-1.png" alt="360 1-1">
      </div>
      <div class="media-cell">
        <video class="autoplay-loop-video" src="assets/360/1-2.mp4" controls autoplay loop muted></video>
      </div>
      <div class="media-cell">
        <img src="assets/360/2-1.png" alt="360 2-1">
      </div>
      <div class="media-cell">
        <video class="autoplay-loop-video" src="assets/360/2-2.mp4" controls autoplay loop muted></video>
      </div>
    </div>

    <div class="media-row">
      <div class="media-cell">
        <img src="assets/NeRF/1-1.png" alt="NeRF 1-1">
      </div>
      <div class="media-cell">
        <video class="autoplay-loop-video" src="assets/NeRF/1-2.mp4" controls autoplay loop muted></video>
      </div>
      <div class="media-cell">
        <img src="assets/NeRF/2-1.png" alt="NeRF 2-1">
      </div>
      <div class="media-cell">
        <video class="autoplay-loop-video" src="assets/NeRF/2-2.mp4" controls autoplay loop muted></video>
      </div>
    </div>

    <h2 class="title is-3" style="font-weight: bold; margin-top: 60px;">Video Style Transfer</h2>
    <div class="content has-text-justified" style="margin-bottom: 20px;">
      <p>
        This task transforms the visual style of a source video into that of a target domain (e.g., converting a realistic video into an animated version) while preserving motion and structure.
      </p>
    </div>
    <div class="media-row">
      <div class="media-cell">
        <video class="autoplay-loop-video" src="assets/V2VAnimate/1-1.mp4" controls autoplay loop muted></video>
      </div>
      <div class="media-cell">
        <video class="autoplay-loop-video" src="assets/V2VAnimate/1-2.mp4" controls autoplay loop muted></video>
      </div>
      <div class="media-cell">
        <video class="autoplay-loop-video" src="assets/V2VAnimate/2-1.mp4" controls autoplay loop muted></video>
      </div>
      <div class="media-cell">
        <video class="autoplay-loop-video" src="assets/V2VAnimate/2-2.mp4" controls autoplay loop muted></video>
      </div>
    </div>

    <h2 class="title is-3" style="font-weight: bold; margin-top: 60px;">Multiple Image Conditions</h2>
    <div class="content has-text-justified" style="margin-bottom: 20px;">
      <p>
        This task generates a video based on two or more image conditions—such as a person and clothing, or a person and an object—capturing the combined semantics in motion.
      </p>
    </div>
    <div class="media-row">
      <div class="media-cell">
        <img src="assets/Advertise/1-1.png" alt="Advertise 1-1">
      </div>
      <div class="media-cell">
        <img src="assets/Advertise/1-2.png" alt="Advertise 1-2">
      </div>
      <div class="media-cell">
        <video class="autoplay-loop-video" src="assets/Advertise/1-3.mp4" controls autoplay loop muted></video>
      </div>
    </div>
    <div class="media-row">
      <div class="media-cell">
        <img src="assets/Advertise/2-1.png" alt="Advertise 2-1">
      </div>
      <div class="media-cell">
        <img src="assets/Advertise/2-2.png" alt="Advertise 2-2">
      </div>
      <div class="media-cell">
        <video class="autoplay-loop-video" src="assets/Advertise/2-3.mp4" controls autoplay loop muted></video>
      </div>
    </div>
    <div class="media-row">
      <div class="media-cell">
        <img src="assets/VITON/1-1.png" alt="VITON 1-1">
      </div>
      <div class="media-cell">
        <img src="assets/VITON/1-2.png" alt="VITON 1-2">
      </div>
      <div class="media-cell">
        <video class="autoplay-loop-video" src="assets/VITON/1-3.mp4" controls autoplay loop muted></video>
      </div>
    </div>
    <div class="media-row">
      <div class="media-cell">
        <img src="assets/VITON/2-1.png" alt="VITON 2-1">
      </div>
      <div class="media-cell">
        <img src="assets/VITON/2-2.png" alt="VITON 2-2">
      </div>
      <div class="media-cell">
        <video class="autoplay-loop-video" src="assets/VITON/2-3.mp4" controls autoplay loop muted></video>
      </div>
    </div>

    <h2 class="title is-3" style="font-weight: bold; margin-top: 60px;">Keyframe Interpolation</h2>
    <div class="content has-text-justified" style="margin-bottom: 20px;">
      <p>
        This task fills in intermediate frames between sparse keyframes to generate a smooth and temporally coherent video.
      </p>
    </div>
    <div class="media-row">
      <div class="media-cell">
        <img src="assets/INTERPOLATE/1-1.png" alt="INTERPOLATE 1-1">
      </div>
      <div class="media-cell">
        <img src="assets/INTERPOLATE/1-2.png" alt="INTERPOLATE 1-2">
      </div>
      <div class="media-cell">
        <img src="assets/INTERPOLATE/1-3.png" alt="INTERPOLATE 1-3">
      </div>
      <div class="media-cell">
        <img src="assets/INTERPOLATE/1-4.png" alt="INTERPOLATE 1-4">
      </div>
      <div class="media-cell">
        <video class="autoplay-loop-video" src="assets/INTERPOLATE/1-5.mp4" controls autoplay loop muted></video>
      </div>
    </div>

    <h2 class="title is-3" style="font-weight: bold; margin-top: 60px;">In-Context Action Transfer</h2>
    <div class="content has-text-justified" style="margin-bottom: 20px;">
      <p>
        This task continues a novel scene by transferring the motion pattern of a reference action video into a new context, guided by the first frame of the new environment.
      </p>
    </div>
    <div class="media-row">
      <div class="media-cell">
        <video class="autoplay-loop-video" src="assets/SSv2/1-1.mp4" controls autoplay loop muted></video>
      </div>
      <div class="media-cell">
        <img src="assets/SSv2/1-2.png" alt="SSv2 1-2">
      </div>
      <div class="media-cell">
        <video class="autoplay-loop-video" src="assets/SSv2/1-3.mp4" controls autoplay loop muted></video>
      </div>
    </div>
  </div>
</section>

<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>TBD</code></pre>
  </div>
</section>

<script>
  function enforceAutoplayLoop(video) {
    // Play on load
    if (video.paused) video.play();
    // Always loop
    video.addEventListener('ended', function() {
      video.currentTime = 0;
      video.play();
    });
    // Prevent seeking to pause only if not paused by user
    video.addEventListener('seeking', function() {
      if (!video.paused) video.play();
    });
  }

  // 동영상 모두 동일하게 0초에서 시작
  function syncAllVideos() {
    const videos = document.querySelectorAll('video');
    videos.forEach(v => {
      try {
        v.currentTime = 0;
        v.play();
      } catch (e) {}
    });
  }

  document.addEventListener('DOMContentLoaded', function() {
    document.querySelectorAll('video').forEach(enforceAutoplayLoop);
    syncAllVideos();
  });

  // Observe for dynamically added/replaced videos
  const observer = new MutationObserver(() => {
    document.querySelectorAll('video').forEach(enforceAutoplayLoop);
    syncAllVideos();
  });
  observer.observe(document.body, { childList: true, subtree: true });
</script>

</body>
</html>
